{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cde6753-c327-4c1d-9ea8-63a1f851ddff",
   "metadata": {},
   "source": [
    "# Lesson 4: Form Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bdf36b-0ddd-4b79-9ea7-b1be3860011b",
   "metadata": {},
   "source": [
    "**Lesson objective**: Incorporate form parsing to the workflow\n",
    "\n",
    "In your previous lesson, you used LlamaParse to parse a resume, and included parsing instructions. You'll do that again this time, but the instructions are going to be more advanced -- you're going to get it to read an application form and convert it into a list of fields that need to be filled in, and return that as a JSON object. You will then incorporate these steps in the workflow you started building in the previous lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "497254a3-476d-401f-9d40-76e9a364756c",
   "metadata": {
    "height": 401
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.gemini import GeminiEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context\n",
    ")\n",
    "from IPython.display import display, HTML\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "180fcb51-4d47-4877-a5b3-f773c64f1f72",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca4f7e",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> üíª &nbsp; <b>To access <code>fake_application_form.pdf</code>, <code>fake_resume.pdf</code>, <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. The form and resume are inside the data folder.\n",
    "\n",
    "<p> ‚¨á &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> üìí &nbsp; For more help, please see the <em>\"Appendix ‚Äì Tips and Help\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad988d7",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> üö®\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d142d4e-48b4-43ec-ac7c-b608a8ba23c7",
   "metadata": {},
   "source": [
    "## Parsing an Application Form with LlamaParse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ada06-8cc7-4c4e-b4fb-268a0515addd",
   "metadata": {},
   "source": [
    "Let's create a parser with our new parsing instructions, including formatting instructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777454c5-31d0-4b23-ac03-f74207fbaf83",
   "metadata": {
    "height": 44
   },
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "# Step 1: Parse the PDF\n",
    "def parse_pdf(file_path: str) -> str:\n",
    "    doc = fitz.open(file_path)\n",
    "    text = ''\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + '\\n'\n",
    "    return text\n",
    "# Step 2: Create Document from parsed text\n",
    "def create_document_from_text(text: str) -> Document:\n",
    "    return Document(text=text)\n",
    "# Step 3: Split Document into Nodes\n",
    "def split_document_into_nodes(document: Document) -> list:\n",
    "    splitter = SentenceSplitter(chunk_size=1024, chunk_overlap=20)\n",
    "    nodes = splitter.get_nodes_from_documents([document])\n",
    "    return nodes\n",
    "# Example usage\n",
    "cv_parser = parse_pdf('data/fake_resume.pdf')\n",
    "document = create_document_from_text(cv_parser)\n",
    "nodes_cv = split_document_into_nodes(document)\n",
    "\n",
    "\n",
    "\n",
    "cv_application = parse_pdf('data/fake_application_form.pdf')\n",
    "document = create_document_from_text(cv_application)\n",
    "nodes_app = split_document_into_nodes(document)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633211a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Big Tech Co. Job Application Form \\nPosition: Senior Web Developer C3 \\nThanks for applying to Big Tech Co.! We are humbled that you would consider working here. \\nPlease fill in the following form to help us get started. \\n \\nFirst Name \\n \\nLast Name  \\n \\nEmail \\n \\nPhone \\n \\nLinkedin \\n \\n \\nProject Portfolio \\n \\n \\nDegree \\n \\nGraduation \\nDate \\n \\nCurrent Job title \\n \\nCurrent \\nEmployer \\n \\nTechnical Skills \\n \\n \\nDescribe why \\nyou‚Äôre a good fit \\nfor this position \\n \\nDo you have 5 \\nyears of \\nexperience in \\nReact?',\n",
       " \"\\u202dSarah Chen\\u202c\\n\\u202dFull Stack Web Developer\\u202c\\n\\u202dEmail:\\u202c\\u202dsarah.chen@email.com\\u202c\\n\\u202dLinkedIn:\\u202c\\u202dlinkedin.com/in/sarahchen\\u202c\\n\\u202dGitHub:\\u202c\\u202dgithub.com/sarahcodes\\u202c\\n\\u202dPortfolio: sarahchen.dev\\u202c\\n\\u202dLocation: San Francisco, CA\\u202c\\n\\u202dProfessional Summary\\u202c\\n\\u202dInnovative Full Stack Web Developer with 6+ years of experience crafting scalable web\\u202c\\n\\u202dapplications and microservices. Specialized in React, Node.js, and cloud architecture. Proven\\u202c\\n\\u202dtrack record of leading technical teams and implementing CI/CD pipelines that reduced\\u202c\\n\\u202ddeployment time by 40%. Passionate about clean code, accessibility, and mentoring junior\\u202c\\n\\u202ddevelopers.\\u202c\\n\\u202dProfessional Experience\\u202c\\n\\u202dSenior Full Stack Developer\\u202c\\n\\u202dTechFlow Solutions\\u202c\\u202d| San Francisco, CA\\u202c\\u202dJanuary 2022\\u202c\\u202d- Present\\u202c\\n\\u202d‚óè\\u202c \\u202dArchitected and implemented a microservices-based\\u202c\\n\\u202de-commerce platform serving 100K+ daily users\\u202c\\n\\u202d‚óè\\u202c \\u202dLed a team of 5 developers in rebuilding the company's\\u202c\\n\\u202dflagship product using React and Node.js\\u202c\\n\\u202d‚óè\\u202c \\u202dImplemented GraphQL API gateway that reduced API\\u202c\\n\\u202dresponse times by 60%\\u202c\\n\\u202d‚óè\\u202c \\u202dEstablished coding standards and review processes that\\u202c\\n\\u202dimproved code quality by 45%\\u202c\\n\\u202dTechnical Skills\\u202c\\n\\u202dFrontend:\\u202c\\n\\u202d‚óè\\u202c \\u202dReact.js, Redux, Next.js, TypeScript\\u202c\\n\\u202d‚óè\\u202c \\u202dVue.js, Nuxt.js\\u202c\\n\\u202d‚óè\\u202c \\u202dHTML5, CSS3, SASS/SCSS\\u202c\\n\\u202d‚óè\\u202c \\u202dJest, React Testing Library\\u202c\\n\\u202d‚óè\\u202c \\u202dWebPack, Babel\\u202c\\n\\u202dBackend:\\u202c\\n\\u202d‚óè\\u202c \\u202dNode.js, Express.js\\u202c\\n\\u202d‚óè\\u202c \\u202dPython, Django\\u202c\\n\\u202d‚óè\\u202c \\u202dGraphQL, REST APIs\\u202c\\n\\u202d‚óè\\u202c \\u202dPostgreSQL, MongoDB\\u202c\\n\\n\\u202d‚óè\\u202c \\u202dMentored 3 junior developers who were promoted to mid-level\\u202c\\n\\u202dpositions\\u202c\\n\\u202dFull Stack Developer\\u202c\\n\\u202dInnovateSoft\\u202c\\u202d| Oakland, CA\\u202c\\u202dMarch 2019 - December 2021\\u202c\\n\\u202d‚óè\\u202c \\u202dDeveloped and maintained 10+ customer-facing applications\\u202c\\n\\u202dusing Vue.js and Django\\u202c\\n\\u202d‚óè\\u202c \\u202dImplemented automated testing suite that increased code\\u202c\\n\\u202dcoverage from 65% to 95%\\u202c\\n\\u202d‚óè\\u202c \\u202dOptimized database queries resulting in 30% faster page load\\u202c\\n\\u202dtimes\\u202c\\n\\u202d‚óè\\u202c \\u202dCollaborated with UX team to implement accessibility features\\u202c\\n\\u202d(WCAG 2.1 compliance)\\u202c\\n\\u202d‚óè\\u202c \\u202dCreated documentation that reduced onboarding time for new\\u202c\\n\\u202ddevelopers by 50%\\u202c\\n\\u202dJunior Web Developer\\u202c\\n\\u202dStartupHub\\u202c\\u202d| San Jose, CA\\u202c\\u202dJune 2017 - February 2019\\u202c\\n\\u202d‚óè\\u202c \\u202dBuilt responsive web applications using React.js and\\u202c\\n\\u202dExpress.js\\u202c\\n\\u202d‚óè\\u202c \\u202dImplemented user authentication system using JWT and\\u202c\\n\\u202dOAuth2.0\\u202c\\n\\u202d‚óè\\u202c \\u202dContributed to migration of legacy PHP applications to modern\\u202c\\n\\u202dJavaScript stack\\u202c\\n\\u202d‚óè\\u202c \\u202dDeveloped RESTful APIs consumed by mobile and web\\u202c\\n\\u202dapplications\\u202c\\n\\u202d‚óè\\u202c \\u202dDocker, Kubernetes\\u202c\\n\\u202dTools & Others:\\u202c\\n\\u202d‚óè\\u202c \\u202dAWS (EC2, S3, Lambda)\\u202c\\n\\u202d‚óè\\u202c \\u202dGit, GitHub Actions\\u202c\\n\\u202d‚óè\\u202c \\u202dJenkins,\")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_app[0].text, nodes_cv[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95399d6d-1abd-4b3d-a7b1-7c9ba34e0c12",
   "metadata": {},
   "source": [
    "A useful thing LLMs can do is turn human-readable formats into machine-readable ones. You will ask the LLM to turn the list into a JSON object with a list of fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d53efc82-cbd2-448d-bc6f-96d6bc1486f7",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "llm = GoogleGenAI(model=\"models/gemini-2.0-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06e38ac6-1e88-46dd-ace4-77241aff9d42",
   "metadata": {
    "height": 163
   },
   "outputs": [],
   "source": [
    "raw_json = llm.complete(\n",
    "    f\"\"\"\n",
    "    This is a parsed form.\n",
    "    Convert it into a JSON object containing only the list \n",
    "    of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "    <form>{nodes_app}</form>. \n",
    "    Return JSON ONLY, no markdown.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe444b5-b18a-4b5b-9a9f-dd0942fff0b9",
   "metadata": {},
   "source": [
    "Here's the raw JSON:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bc89e72-76e0-4cfd-904b-0d3dd058532b",
   "metadata": {
    "height": 29
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"fields\": [\\n    \"First Name\",\\n    \"Last Name\",\\n    \"Email\",\\n    \"Phone\",\\n    \"Linkedin\",\\n    \"Project Portfolio\",\\n    \"Degree\",\\n    \"Graduation Date\",\\n    \"Current Job title\",\\n    \"Current Employer\",\\n    \"Technical Skills\",\\n    \"Describe why you‚Äôre a good fit for this position\",\\n    \"Do you have 5 years of experience in React?\"\\n  ]\\n}\\n```'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_json.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbf060-bed0-40a1-9173-f85eaa7e4978",
   "metadata": {},
   "source": [
    "And you can print out the fields one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de79c4-dbda-4103-baa1-5b315af6c1e1",
   "metadata": {
    "height": 80
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fields \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_json\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m fields:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(field)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "for field in fields:\n",
    "    print(field)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dabc0b2-1258-45c9-954a-67de4baca6c9",
   "metadata": {},
   "source": [
    "Now that you know how to parse the job application form, you will add this processing to the workflow of lesson 3. You will do that in two steps as shown in this figure:\n",
    "\n",
    "<img width=\"700\" src=\"images/L4-diagrams.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffc1088-2bd3-4ce8-a491-e8acd9cbde6b",
   "metadata": {},
   "source": [
    "## Adding a Form Parser to the Workflow (first update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbb61b-8e74-45d0-ae26-d8ecc40b42c7",
   "metadata": {},
   "source": [
    "Now let's take the workflow you built in the last lesson and add your parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436f51ba-760d-4af6-8da1-8088e7c8ebcd",
   "metadata": {
    "height": 97
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79094e64-7aa0-47d5-8974-8b3b2200d111",
   "metadata": {},
   "source": [
    "Your `set_up` step now emits a `ParseFormEvent` which triggers your new step, `parse_form`. For the moment you can leave the ask_questions step untouched, it will be updated in another section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f30a2e-2c39-411a-917c-b78549e5eef1",
   "metadata": {
    "height": 1336
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # you no longer need a query to be passed in, \n",
    "        # you'll be generating the queries instead \n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> QueryEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form. \n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result.text}</form>. \n",
    "            Return JSON ONLY, no markdown.\n",
    "            \"\"\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        for field in fields:\n",
    "            print(field)\n",
    "        return StopEvent(result=\"Dummy event\")\n",
    "\n",
    "    # will be edited in the next section\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> StopEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return StopEvent(result=response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905709d6-ad52-4514-a75e-2bae2cfbb802",
   "metadata": {
    "height": 97
   },
   "outputs": [],
   "source": [
    "w = RAGWorkflow(timeout=60, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a656e32f-19ce-4f45-883e-5c89cb800d9e",
   "metadata": {},
   "source": [
    "## Generating Questions (second update)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f4a3ee-0d76-4402-9221-12dfd2755269",
   "metadata": {},
   "source": [
    "Excellent! Your workflow knows what fields it needs answers for. In this next iteration, you can fire off one `QueryEvent` for each of the fields, so they'll be executed concurrently (we talked about doing concurrent steps in Lesson 2). \n",
    "\n",
    "<img width=\"700\" src=\"images/L4-diag-2.png\">\n",
    "\n",
    "\n",
    "The changes you're going to make are:\n",
    "* Generate a `QueryEvent` for each of the questions you pulled out of the form\n",
    "* Create a `fill_in_application` step which will take all the responses to the questions and aggregate them into a coherent response\n",
    "* Add a `ResponseEvent` to pass the results of queries to `fill_in_application`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479183ef-c912-4fb9-8b5d-348e1942e713",
   "metadata": {
    "height": 182
   },
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "    field: str\n",
    "\n",
    "# new!\n",
    "class ResponseEvent(Event):\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a16626b-75c7-4b2f-84c5-94688530cc89",
   "metadata": {
    "height": 1863
   },
   "outputs": [],
   "source": [
    "class RAGWorkflow(Workflow):\n",
    "    \n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # define the LLM to work with\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        # ingest the data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # you've already ingested the resume document\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # parse and load the resume document\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # you no longer need a query to be passed in, \n",
    "        # you'll be generating the queries instead \n",
    "        # let's pass the application form to a new step to parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> QueryEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            base_url=os.getenv(\"LLAMA_CLOUD_BASE_URL\"),\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"\"\"\n",
    "            This is a parsed form. \n",
    "            Convert it into a JSON object containing only the list \n",
    "            of fields to be filled in, in the form {{ fields: [...] }}. \n",
    "            <form>{result.text}</form>. \n",
    "            Return JSON ONLY, no markdown.\n",
    "            \"\"\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        # new!\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=f\"How would you answer this question about the candidate? {field}\"\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "    # new!\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> StopEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "        return StopEvent(result=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf0ba9-d3e7-4380-be07-368b6ec41f29",
   "metadata": {
    "height": 114
   },
   "outputs": [],
   "source": [
    "w = RAGWorkflow(timeout=120, verbose=False)\n",
    "result = await w.run(\n",
    "    resume_file=\"data/fake_resume.pdf\",\n",
    "    application_form=\"data/fake_application_form.pdf\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ff7243",
   "metadata": {},
   "source": [
    "## Workflow Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0a1393-35b9-4fe9-a741-2dbfbeba73c9",
   "metadata": {},
   "source": [
    "You can visualize the workflow you just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6416a1f-c2c9-478b-b290-8cd89998da35",
   "metadata": {
    "height": 80
   },
   "outputs": [],
   "source": [
    "WORKFLOW_FILE = \"workflows/form_parsing_workflow.html\"\n",
    "draw_all_possible_flows(w, filename=WORKFLOW_FILE)\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38d509-755f-48f0-b340-1fa99314b531",
   "metadata": {},
   "source": [
    "## Cool!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e1158-b7ef-4b65-8a36-1fe628813d95",
   "metadata": {},
   "source": [
    "Your workflow takes all the fields in the form and generates plausible answers for all of them. There are a couple of fields where I think it can do better, and in the next lesson you'll add the ability to give that feedback to the agent and get it to try again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
