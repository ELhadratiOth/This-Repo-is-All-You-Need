{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geh6127Noqry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "488c4602-9b36-4ba4-8392-514b3fba587a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.12.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.11)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.14)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.29)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.25.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (0.3.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain_community) (2.10.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain_community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community beautifulsoup4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# speech.txt content\n",
        "In the ever-evolving world of artificial intelligence, machine learning has emerged as one of the most influential fields. It encompasses a variety of techniques, including supervised, unsupervised, and reinforcement learning. Each of these methods serves a distinct purpose in solving complex problems, from predicting future trends to optimizing decision-making processes.\n",
        "\n",
        "Supervised learning, one of the most common techniques, involves training a model on labeled data to make predictions or classifications. This approach is widely used in fields like healthcare, finance, and marketing. For example, in healthcare, machine learning models can predict the likelihood of diseases based on historical patient data.\n",
        "\n",
        "Unsupervised learning, on the other hand, focuses on identifying patterns and structures within data without prior labeling. It is often applied in scenarios like customer segmentation, where the goal is to discover hidden groupings within a dataset. Techniques such as clustering and dimensionality reduction are commonly used in this approach.\n",
        "\n",
        "Reinforcement learning is a type of learning that is based on trial and error. An agent interacts with an environment, making decisions and receiving rewards or penalties based on those actions. Over time, the agent learns to make better decisions to maximize its rewards. This approach has been used in robotics, game-playing, and autonomous systems.\n",
        "\n",
        "As AI continues to advance, new methodologies and applications are being developed, driving innovation across industries. The integration of machine learning into everyday technology is transforming how businesses operate and how individuals interact with technology.\n"
      ],
      "metadata": {
        "id": "lXvLUlN1zW0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "loader = TextLoader(\"speech.txt\")"
      ],
      "metadata": {
        "id": "s0PDtBmOxigQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_doc = loader.load()\n",
        "text_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJhALDl00VYG",
        "outputId": "44bf9c03-7cf3-410a-9639-bdb8fa5b30f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'speech.txt'}, page_content='In the ever-evolving world of artificial intelligence, machine learning has emerged as one of the most influential fields. It encompasses a variety of techniques, including supervised, unsupervised, and reinforcement learning. Each of these methods serves a distinct purpose in solving complex problems, from predicting future trends to optimizing decision-making processes.\\n\\nSupervised learning, one of the most common techniques, involves training a model on labeled data to make predictions or classifications. This approach is widely used in fields like healthcare, finance, and marketing. For example, in healthcare, machine learning models can predict the likelihood of diseases based on historical patient data.\\n\\nUnsupervised learning, on the other hand, focuses on identifying patterns and structures within data without prior labeling. It is often applied in scenarios like customer segmentation, where the goal is to discover hidden groupings within a dataset. Techniques such as clustering and dimensionality reduction are commonly used in this approach.\\n\\nReinforcement learning is a type of learning that is based on trial and error. An agent interacts with an environment, making decisions and receiving rewards or penalties based on those actions. Over time, the agent learns to make better decisions to maximize its rewards. This approach has been used in robotics, game-playing, and autonomous systems.\\n\\nAs AI continues to advance, new methodologies and applications are being developed, driving innovation across industries. The integration of machine learning into everyday technology is transforming how businesses operate and how individuals interact with technology.\\nMachine Learning (ML) is a subset of artificial intelligence (AI) that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data, without being explicitly programmed. Machine learning systems use data to identify patterns and insights, improving their performance over time as they are exposed to more data.')]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "iiCel92y0VVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import bs4\n",
        "loader = WebBaseLoader(\n",
        "    web_path=\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    bs_kwargs={\"parse_only\": bs4.SoupStrainer(\n",
        "        class_=(\"post-title\", \"post-content\")\n",
        "    )}\n",
        ")\n",
        "text_doc = loader.load()\n"
      ],
      "metadata": {
        "id": "dq-KDl1e0VTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Vozf3xjj0VQn",
        "outputId": "3bf6f272-a701-46d2-85c1-2469ccb101e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='\\n      LLM Powered Autonomous Agents\\n    Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\nFig. 2.  Examples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\nFig. 3. Illustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\nFig. 4. Experiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)\\nChain of Hindsight (CoH; Liu et al. 2023) encourages the model to improve on its own outputs by explicitly presenting it with a sequence of past outputs, each annotated with feedback. Human feedback data is a collection of $D_h = \\\\{(x, y_i , r_i , z_i)\\\\}_{i=1}^n$, where $x$ is the prompt, each $y_i$ is a model completion, $r_i$ is the human rating of $y_i$, and $z_i$ is the corresponding human-provided hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.\\nTo avoid overfitting, CoH adds a regularization term to maximize the log-likelihood of the pre-training dataset. To avoid shortcutting and copying (because there are many common words in feedback sequences), they randomly mask 0% - 5% of past tokens during training.\\nThe training dataset in their experiments is a combination of WebGPT comparisons, summarization from human feedback and human preference dataset.\\n\\nFig. 5. After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)\\nThe idea of CoH is to present a history of sequentially improved outputs  in context and train the model to take on the trend to produce better outputs. Algorithm Distillation (AD; Laskin et al. 2023) applies the same idea to cross-episode trajectories in reinforcement learning tasks, where an algorithm is encapsulated in a long history-conditioned policy. Considering that an agent interacts with the environment many times and in each episode the agent gets a little better, AD concatenates this learning history and feeds that into the model. Hence we should expect the next predicted action to lead to better performance than previous trials. The goal is to learn the process of RL instead of training a task-specific policy itself.\\n\\nFig. 6. Illustration of how Algorithm Distillation (AD) works. (Image source: Laskin et al. 2023).\\nThe paper hypothesizes that any algorithm that generates a set of learning histories can be distilled into a neural network by performing behavioral cloning over actions. The history data is generated by a set of source policies, each trained for a specific task. At the training stage, during each RL run, a random task is sampled and a subsequence of multi-episode history is used for training, such that the learned policy is task-agnostic.\\nIn reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.\\nIn comparison with three baselines, including ED (expert distillation, behavior cloning with expert trajectories instead of learning history), source policy (used for generating trajectories for distillation by UCB), RL^2 (Duan et al. 2017; used as upper bound since it needs online RL), AD demonstrates in-context RL with performance getting close to RL^2 despite only using offline RL and learns much faster than other baselines. When conditioned on partial training history of the source policy, AD also improves much faster than ED baseline.\\n\\nFig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:\\n\\nLSH (Locality-Sensitive Hashing): It introduces a hashing function such that similar input items are mapped to the same buckets with high probability, where the number of buckets is much smaller than the number of inputs.\\nANNOY (Approximate Nearest Neighbors Oh Yeah): The core data structure are random projection trees, a set of binary trees where each non-leaf node represents a hyperplane splitting the input space into half and each leaf stores one data point. Trees are built independently and at random, so to some extent, it mimics a hashing function. ANNOY search happens in all the trees to iteratively search through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.\\nHNSW (Hierarchical Navigable Small World): It is inspired by the idea of small world networks where most nodes can be reached by any other nodes within a small number of steps; e.g. “six degrees of separation” feature of social networks. HNSW builds hierarchical layers of these small-world graphs, where the bottom layers contain the actual data points. The layers in the middle create shortcuts to speed up search. When performing a search, HNSW starts from a random node in the top layer and navigates towards the target. When it can’t get any closer, it moves down to the next layer, until it reaches the bottom layer. Each move in the upper layers can potentially cover a large distance in the data space, and each move in the lower layers refines the search quality.\\nFAISS (Facebook AI Similarity Search): It operates on the assumption that in high dimensional space, distances between nodes follow a Gaussian distribution and thus there should exist clustering of data points. FAISS applies vector quantization by partitioning the vector space into clusters and then refining the quantization within clusters. Search first looks for cluster candidates with coarse quantization and then further looks into each cluster with finer quantization.\\nScaNN (Scalable Nearest Neighbors): The main innovation in ScaNN is anisotropic vector quantization. It quantizes a data point $x_i$ to $\\\\tilde{x}_i$ such that the inner product $\\\\langle q, x_i \\\\rangle$ is as similar to the original distance of $\\\\angle q, \\\\tilde{x}_i$ as possible, instead of picking the closet quantization centroid points.\\n\\n\\nFig. 9. Comparison of MIPS algorithms, measured in recall@10. (Image source: Google Blog, 2020)\\nCheck more MIPS algorithms and performance comparison in ann-benchmarks.com.\\nComponent Three: Tool Use#\\nTool use is a remarkable and distinguishing characteristic of human beings. We create, modify and utilize external objects to do things that go beyond our physical and cognitive limits. Equipping LLMs with external tools can significantly extend the model capabilities.\\n\\nFig. 10. A picture of a sea otter using rock to crack open a seashell, while floating in the water. While some other animals can use tools, the complexity is not comparable with humans. (Image source: Animals using tools)\\nMRKL (Karpas et al. 2022), short for “Modular Reasoning, Knowledge and Language”, is a neuro-symbolic architecture for autonomous agents. A MRKL system is proposed to contain a collection of “expert” modules and the general-purpose LLM works as a router to route inquiries to the best suitable expert module. These modules can be neural (e.g. deep learning models) or symbolic (e.g. math calculator, currency converter, weather API).\\nThey did an experiment on fine-tuning LLM to call a calculator, using arithmetic as a test case. Their experiments showed that it was harder to solve verbal math problems than explicitly stated math problems because LLMs (7B Jurassic1-large model) failed to extract the right arguments for the basic arithmetic reliably. The results highlight when the external symbolic tools can work reliably, knowing when to and how to use the tools are crucial, determined by the LLM capability.\\nBoth TALM (Tool Augmented Language Models; Parisi et al. 2022) and Toolformer (Schick et al. 2023) fine-tune a LM to learn to use external tool APIs. The dataset is expanded based on whether a newly added API call annotation can improve the quality of model outputs. See more details in the “External APIs” section of Prompt Engineering.\\nChatGPT Plugins and OpenAI API  function calling are good examples of LLMs augmented with tool use capability working in practice. The collection of tool APIs can be provided by other developers (as in Plugins) or self-defined (as in function calls).\\nHuggingGPT (Shen et al. 2023) is a framework to use ChatGPT as the task planner to select models available in HuggingFace platform according to the model descriptions and summarize the response based on the execution results.\\n\\nFig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:\\n\\nThe AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\\n\\n(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:\\n\\nGiven the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\\n\\n(3) Task execution: Expert models execute on the specific tasks and log results.\\nInstruction:\\n\\nWith the input and the inference results, the AI assistant needs to describe the process and results. The previous stages can be formed as - User Input: {{ User Input }}, Task Planning: {{ Tasks }}, Model Selection: {{ Model Assignment }}, Task Execution: {{ Predictions }}. You must first answer the user\\'s request in a straightforward manner. Then describe the task process and show your analysis and model inference results to the user in the first person. If inference results contain a file path, must tell the user the complete file path.\\n\\n(4) Response generation: LLM receives the execution results and provides summarized results to users.\\nTo put HuggingGPT into real world usage, a couple challenges need to solve: (1) Efficiency improvement is needed as both LLM inference rounds and interactions with other models slow down the process; (2) It relies on a long context window to communicate over complicated task content; (3) Stability improvement of LLM outputs and external model services.\\nAPI-Bank (Li et al. 2023) is a benchmark for evaluating the performance of tool-augmented LLMs. It contains 53 commonly used API tools, a complete tool-augmented LLM workflow, and 264 annotated dialogues that involve 568 API calls. The selection of APIs is quite diverse, including search engines, calculator, calendar queries, smart home control, schedule management, health data management, account authentication workflow and more. Because there are a large number of APIs, LLM first has access to API search engine to find the right API to call and then uses the corresponding documentation to make a call.\\n\\nFig. 12. Pseudo code of how LLM makes an API call in API-Bank. (Image source: Li et al. 2023)\\nIn the API-Bank workflow, LLMs need to make a couple of decisions and at each step we can evaluate how accurate that decision is. Decisions include:\\n\\nWhether an API call is needed.\\nIdentify the right API to call: if not good enough, LLMs need to iteratively modify the API inputs (e.g. deciding search keywords for Search Engine API).\\nResponse based on the API results: the model can choose to refine and call again if results are not satisfied.\\n\\nThis benchmark evaluates the agent’s tool use capabilities at three levels:\\n\\nLevel-1 evaluates the ability to call the API. Given an API’s description, the model needs to determine whether to call a given API, call it correctly, and respond properly to API returns.\\nLevel-2 examines the ability to retrieve the API. The model needs to search for possible APIs that may solve the user’s requirement and learn how to use them by reading documentation.\\nLevel-3 assesses the ability to plan API beyond retrieve and call. Given unclear user requests (e.g. schedule group meetings, book flight/hotel/restaurant for a trip), the model may have to conduct multiple API calls to solve it.\\n\\nCase Studies#\\nScientific Discovery Agent#\\nChemCrow (Bran et al. 2023) is a domain-specific example in which LLM is augmented with 13 expert-designed tools to accomplish tasks across organic synthesis, drug discovery, and materials design. The workflow, implemented in LangChain, reflects what was previously described in the ReAct and MRKLs and combines CoT reasoning with tools relevant to the tasks:\\n\\nThe LLM is provided with a list of tool names, descriptions of their utility, and details about the expected input/output.\\nIt is then instructed to answer a user-given prompt using the tools provided when necessary. The instruction suggests the model to follow the ReAct format - Thought, Action, Action Input, Observation.\\n\\nOne interesting observation is that while the LLM-based evaluation concluded that GPT-4 and ChemCrow perform nearly equivalently, human evaluations with experts oriented towards the completion and chemical correctness of the solutions showed that ChemCrow outperforms GPT-4 by a large margin. This indicates a potential problem with using LLM to evaluate its own performance on domains that requires deep expertise. The lack of expertise may cause LLMs not knowing its flaws and thus cannot well judge the correctness of task results.\\nBoiko et al. (2023) also looked into LLM-empowered agents for scientific discovery, to handle autonomous design, planning, and performance of complex scientific experiments. This agent can use tools to browse the Internet, read documentation, execute code, call robotics experimentation APIs and leverage other LLMs.\\nFor example, when requested to \"develop a novel anticancer drug\", the model came up with the following reasoning steps:\\n\\ninquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\nFig. 13. The generative agent architecture. (Image source: Park et al. 2023)\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes\\n\\nCommands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\\n\\nYou should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:\\n\\nYou will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code’s language, and CODE is the code:\\nFILENAME\\nCODE\\nYou will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\nPython toolbelt preferences:\\n\\npytest\\ndataclasses\\n\\n\\nConversatin samples:\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\\\nInclude module dependency or package manager dependency definition file.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\\\\nUseful to know:\\\\nYou almost always put different classes in different files.\\\\nFor Python, you always create an appropriate requirements.txt file.\\\\nFor NodeJS, you always create an appropriate package.json file.\\\\nYou always add a comment briefly describing the purpose of the function definition.\\\\nYou try to add comments explaining very complex bits of logic.\\\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\\\npackage/project.\\\\n\\\\n\\\\nPython toolbelt preferences:\\\\n- pytest\\\\n- dataclasses\\\\n\"\\n  },\\n #  … same conversation as earlier, ended with \"Make your own assumptions and state them explicitly before starting\".\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Assumptions:\\\\n1. Model: The model will contain the game\\'s data, such as level information, character states, and enemy positions.\\\\n2. View: The view will handle the game\\'s visuals, including rendering the game objects, backgrounds, and updating the display.\\\\n3. Controller: The controller will manage user input, such as keyboard controls, and update the model accordingly.\\\\n\\\\nWith these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"Please now remember the steps:\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nFirst lay out the names of the core classes, functions, methods that will be necessary, As well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nPlease note that the code should be fully functional. No placeholders.\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"\\n  }\\n]\\nChallenges#\\nAfter going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\\n\\n\\nFinite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\\n\\nOr\\n@article{weng2023agent,\\n  title   = \"LLM-powered Autonomous Agents\",\\n  author  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2023\",\\n  month   = \"Jun\",\\n  url     = \"https://lilianweng.github.io/posts/2023-06-23-agent/\"\\n}\\nReferences#\\n[1] Wei et al. “Chain of thought prompting elicits reasoning in large language models.” NeurIPS 2022\\n[2] Yao et al. “Tree of Thoughts: Dliberate Problem Solving with Large Language Models.” arXiv preprint arXiv:2305.10601 (2023).\\n[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).\\n[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).\\n[16] Shen et al. “HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace” arXiv preprint arXiv:2303.17580 (2023).\\n[17] Bran et al. “ChemCrow: Augmenting large-language models with chemistry tools.” arXiv preprint arXiv:2304.05376 (2023).\\n[18] Boiko et al. “Emergent autonomous scientific research capabilities of large language models.” arXiv preprint arXiv:2304.05332 (2023).\\n[19] Joon Sung Park, et al. “Generative Agents: Interactive Simulacra of Human Behavior.” arXiv preprint arXiv:2304.03442 (2023).\\n[20] AutoGPT. https://github.com/Significant-Gravitas/Auto-GPT\\n[21] GPT-Engineer. https://github.com/AntonOsika/gpt-engineer\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "RzbhrIi4_6ff",
        "outputId": "78e070ff-eda1-434b-c00a-244c752e292d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/298.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "loader = PyPDFLoader(\"book.pdf\")\n",
        "docs = loader.load()\n",
        "docs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yTtUnBTo0VN5",
        "outputId": "9c9f5205-8ccc-4d50-b4e3-ff338f5c7847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'book.pdf', 'page': 0}, page_content='PAGE 1\\nFounder, DeepLearning.AI\\nCollected Insights\\nfrom Andrew Ng\\nHow to \\nBuild\\nYour\\nCareer\\nin AI\\nA Simple Guide\\n'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 1}, page_content='PAGE 2\\n\"AI is the new \\nelectricity. It will \\ntransform and improve \\nall areas of human life.\"\\nAndrew Ng'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 2}, page_content='PAGE 3\\nTable of \\nContents\\nIntroduction: Coding AI is the New Literacy.\\nChapter 1: Three Steps to Career Growth.\\nChapter 2: Learning Technical Skills for a \\nPromising AI Career.\\nChapter 3: Should You Learn Math to Get a Job \\nin AI?\\nChapter 4: Scoping Successful AI Projects.\\nChapter 5: Finding Projects that Complement \\nYour Career Goals.\\nChapter 6: Building a Portfolio of Projects that \\nShows Skill Progression.\\nChapter 7: A Simple Framework for Starting Your AI \\nJob Search.\\nChapter 8: Using Informational Interviews to Find \\nthe Right Job.\\nChapter 9: Finding the Right AI Job for You.\\nChapter 10: Keys to Building a Career in AI.\\nChapter 11: Overcoming Imposter Syndrome.\\nFinal Thoughts: Make Every Day Count.\\nLEARNING\\nPROJECTS\\nJOB'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 3}, page_content='PAGE 4\\nCoding AI Is the New Literacy\\nToday we take it for granted that many people know how to read and write. Someday, I hope, \\nit will be just as common that people know how to write code, specifically for AI.\\nSeveral hundred years ago, society didn’t view language literacy as a necessary skill. A small \\nnumber of people learned to read and write, and everyone else let them do the reading and \\nwriting. It took centuries for literacy to spread, and now society is far richer for it.\\nWords enable deep human-to-human communication. Code is the deepest form of human-to-\\nmachine communication. As machines become more central to daily life, that communication \\nbecomes ever more important.\\nTraditional software engineering — writing programs that explicitly tell a computer sequences \\nof steps to execute — has been the main path to code literacy. Many introductory programming \\nclasses use creating a video game or building a website as examples. But AI, machine learning, \\nand data science offer a new paradigm in which computers extract knowledge from data. This \\ntechnology offers an even better pathway to coding.\\nMany Sundays, I buy a slice of pizza from my neighborhood pizza parlor. The gentleman \\nbehind the counter has little reason to learn how to build a video game or write his own \\nwebsite software (beyond personal growth and the pleasure of gaining a new skill).\\nBut AI and data science have great value even for a pizza maker. A linear regression model might \\nenable him to better estimate demand so he can optimize the restaurant’s staffing and supply \\nchain. He could better predict sales of Hawaiian pizza — my favorite! — so he could make more \\nHawaiian pies in advance and reduce the amount of time customers had to wait for them.\\nUses of AI and data science can be found in almost any situation that produces data.  Thus, \\na wide variety of professions will find more uses for custom AI applications and data-derived \\ninsights than for traditional software engineering. This makes literacy in AI-oriented coding \\neven more valuable than traditional coding. It could enable countless individuals to harness \\ndata to make their lives richer.\\nI hope the promise of building basic AI applications, even more than that of building basic \\ntraditional software, encourages more people to learn how to code. If society embraces this \\nnew form of literacy as it has the ability to read and write, we will all benefit.\\nIntroduction'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 4}, page_content='PAGE 5\\nThree Steps to \\nCareer Growth\\nCHAPTER 1'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 5}, page_content='PAGE 6\\nThe rapid rise of AI has led to a rapid rise in AI jobs, and many people are building exciting \\ncareers in this field. A career is a decades-long journey, and the path is not straightforward. \\nOver many years, I’ve been privileged to see thousands of students, as well as engineers in \\ncompanies large and small, navigate careers in AI.\\n \\nHere’s a framework for charting your own course.\\nLater, you will work \\non finding a job. \\nThroughout this \\nprocess, you’ll continue \\nto learn and work on \\nmeaningful projects. \\nChapters with the\\nfocus on a job search.\\nThree key steps of career growth are learning foundational skills, working on projects (to \\ndeepen your skills, build a portfolio, and create impact), and finding a job. These steps stack \\non top of each other:\\nThree Steps to Career Growth\\nLEARNING PROJECTS JOB\\nCHAPTER 1\\nInitially, you \\nfocus on learning \\nfoundational skills. \\nChapters with the \\ncover topics about \\nlearning foundational \\ntechnical skills. \\nAfter having gained \\nfoundational technical \\nskills, you will begin \\nworking on projects. \\nDuring this period, you’ll \\nalso keep learning. \\nChapters with the     \\nfocus on projects. '),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 6}, page_content='PAGE 7\\nThese phases apply in a wide \\nrange of professions, but AI \\ninvolves unique elements.\\nFor example:\\nThree Steps to Career Growth\\nAI is nascent, and many technologies are still evolving. While the \\nfoundations of machine learning and deep learning are maturing — \\nand coursework is an efficient way to master them — beyond these \\nfoundations, keeping up-to-date with changing technology is more \\nimportant in AI than fields that are more mature.\\nLearning foundational skills is a career-long process:\\nThis can make it challenging to find a suitable project, estimate the project’s \\ntimeline and return on investment, and set expectations. In addition, the \\nhighly iterative nature of AI projects leads to special challenges in project \\nmanagement: How can you come up with a plan for building a system \\nwhen you don’t know in advance how long it will take to achieve the target \\naccuracy? Even after the system has hit the target, further iteration may \\nbe necessary to address post-deployment drift.\\nWorking on projects often means collaborating with \\nstakeholders who lack expertise in AI:\\nWhile searching for a job in AI can be similar to searching for a job in \\nother sectors, there are also important differences. Many companies are \\nstill trying to figure out which AI skills they need, and how to hire people \\nwho have them. Things you’ve worked on may be significantly different \\nthan anything your interviewer has seen, and you’re more likely to have to \\neducate potential employers about some elements of your work.\\nInconsistent opinions on AI skills and jobs roles: \\nCHAPTER 1\\nAs you go through each step, you should also build a supportive community. Having friends and \\nallies who can help you — and who you strive to help — makes the path easier. This is true whether \\nyou’re taking your first steps or you’ve been on the journey for years.\\nLEARNING\\nPROJECTS\\nJOB'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 7}, page_content='PAGE 8\\nLearning Technical \\nSkills for a Promising \\nAI Career\\nCHAPTER 2\\nLEARNING'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 8}, page_content='PAGE 9\\nIn the previous chapter, I introduced three key steps for building a career in AI: learning \\nfoundational technical skills, working on projects, and finding a job, all of which is supported \\nby being part of a community. In this chapter, I’d like to dive more deeply into the first step: \\nlearning foundational skills.\\nMore research papers have been published on AI than anyone can read in a lifetime. So, when \\nlearning, it’s critical to prioritize topic selection. I believe the most important topics for a technical \\ncareer in machine learning are:\\nFoundational machine learning skills: For example, it’s important to understand models such \\nas linear regression, logistic regression, neural networks, decision trees, clustering, and anomaly \\ndetection. Beyond specific models, it’s even more important to understand the core concepts \\nbehind how and why machine learning works, such as bias/variance, cost functions, regularization, \\noptimization algorithms, and error analysis.\\nDeep learning: This has become such a large fraction of machine learning that it’s hard to excel \\nin the field without some understanding of it! It’s valuable to know the basics of neural networks, \\npractical skills for making them work (such as hyperparameter tuning), convolutional networks, \\nsequence models, and transformers.\\nSoftware development: While you can get a job and make huge contributions with only machine \\nlearning modeling skills, your job opportunities will increase if you can also write good software \\nto implement complex AI systems. These skills include programming fundamentals, data \\nstructures (especially those that relate to machine learning, such as data frames), algorithms \\n(including those related to databases and data manipulation), software design, familiarity with \\nPython, and familiarity with key libraries such as TensorFlow or PyTorch, and scikit-learn.\\nMath relevant to machine learning: Key areas include linear algebra (vectors, matrices, and various \\nmanipulations of them) as well as probability and statistics (including discrete and continuous \\nprobability, standard probability distributions, basic rules such as independence and Bayes’ rule, \\nand hypothesis testing). In addition, exploratory data analysis (EDA) — using visualizations and other \\nmethods to systematically explore a dataset — is an underrated skill. I’ve found EDA particularly \\nuseful in data-centric AI development, where analyzing errors and gaining insights can really help \\ndrive progress! Finally, a basic intuitive understanding of calculus will also help. The math needed \\nto do machine learning well has been changing. For instance, although some tasks require calculus, \\nimproved automatic differentiation software makes it possible to invent and implement new neural \\nnetwork architectures without doing any calculus. This was almost impossible a decade ago.\\nLearning Technical Skills For a Promising AI Career CHAPTER 2'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 9}, page_content='PAGE 10\\nThis is a lot to learn!\\nEven after you master everything on this list, I hope you’ll keep learning and continue to deepen \\nyour technical knowledge. I’ve known many machine learning engineers who benefitted from \\ndeeper skills in an application area such as natural language processing or computer vision, or in \\na technology area such as probabilistic graphical models or building scalable software systems.\\nHow do you gain these skills? There’s a lot of good content on the internet, and in theory, \\nreading dozens of web pages could work. But when the goal is deep understanding, reading \\ndisjointed web pages is inefficient because they tend to repeat each other, use inconsistent \\nterminology (which slows you down), vary in quality, and leave gaps. That’s why a good course \\n— in which a body of material has been organized into a coherent and logical form — is often the \\nmost time-efficient way to master a meaningful body of knowledge. When you’ve absorbed the \\nknowledge available in courses, you can switch over to research papers and other resources.\\nFinally, no one can cram everything they need to know over a weekend or even a month. Everyone I \\nknow who’s great at machine learning is a lifelong learner. Given how quickly our field is changing, \\nthere’s little choice but to keep learning if you want to keep up.\\nHow can you maintain a steady pace of learning for years? If you can cultivate the habit of \\nlearning a little bit every week, you can make significant progress with what feels like less effort.\\nLearning Technical Skills For a Promising AI Career CHAPTER 2\\n'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 10}, page_content='PAGE 11\\nThe Best Way to Build \\na New Habit\\nOne of my favorite books is BJ Fogg’s, Tiny Habits: The Small Changes That Change \\nEverything. Fogg explains that the best way to build a new habit is to start small \\nand succeed, rather than start  too big and fail. For example, rather than trying to \\nexercise for 30 minutes a day, he recommends aspiring to do just one push-up, and \\ndoing it consistently.\\nThis approach may be helpful to those of you who want to spend more time studying. \\nIf you start by holding yourself accountable for watching, say, 10 seconds of an \\neducational video every day — and you do so consistently — the habit of studying daily \\nwill grow naturally. Even if you learn nothing in that 10 seconds, you’re establishing the \\nhabit of studying a little every day. On some days, maybe you’ll end up studying for an \\nhour or longer.'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 11}, page_content='PAGE 12\\nShould You \\nLearn Math to \\nGet a Job in AI? \\nCHAPTER 3\\nLEARNING'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 12}, page_content='PAGE 13\\nShould you Learn Math to Get a Job in AI? CHAPTER 3\\nIs math a foundational skill for AI? It’s always nice to know more math! But there’s so much to \\nlearn that, realistically, it’s necessary to prioritize. Here’s how you might go about strengthening \\nyour math background.\\nTo figure out what’s important to know, I find it useful to ask what you need to know to make \\nthe decisions required for the work you want to do. At DeepLearning.AI, we frequently ask, \\n“What does someone need to know to accomplish their goals?” The goal might be building a \\nmachine learning model, architecting a system, or passing a job interview.\\nUnderstanding the math behind algorithms you use is often helpful, since it enables you to \\ndebug them. But the depth of knowledge that’s useful changes over time. As machine learning \\ntechniques mature and become more reliable and turnkey, they require less debugging, and a \\nshallower understanding of the math involved may be sufficient to make them work.\\nFor instance, in an earlier era of machine learning, linear algebra libraries for solving linear \\nsystems of equations (for linear regression) were immature. I had to understand how these \\nlibraries worked so I could choose among different libraries and avoid numerical roundoff \\npitfalls. But this became less important as numerical linear algebra libraries matured.\\nDeep learning is still an emerging technology, so when you train a neural network and the \\noptimization algorithm struggles to converge, understanding the math behind gradient \\ndescent, momentum, and the Adam optimization algorithm will help you make better decisions. \\nSimilarly, if your neural network does something funny — say, it makes bad predictions on \\nimages of a certain resolution, but not others — understanding the math behind neural network \\narchitectures puts you in a better position to figure out what to do.\\nOf course, I also encourage learning driven by curiosity. If something interests you, go ahead \\nand learn it regardless of how useful it might turn out to be!  Maybe this will lead to a creative \\nspark or technical breakthrough.\\nHow much math do you need to know to be a machine learning engineer?'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 13}, page_content='PAGE 14\\nScoping Successful \\nAI Projects\\nCHAPTER 4\\nPROJECTS'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 14}, page_content='PAGE 15\\nOne of the most important skills of an AI architect is the ability to identify ideas that are worth \\nworking on. These next few chapters will discuss finding and working on projects so you can gain \\nexperience and build your portfolio. \\nOver the years, I’ve had fun applying machine learning to manufacturing, healthcare, climate \\nchange, agriculture, ecommerce, advertising, and other industries. How can someone who’s not \\nan expert in all these sectors find meaningful projects within them? Here are five steps to help \\nyou scope projects.\\nIdentify a business problem (not an AI problem). I like to find \\na domain expert and ask, “What are the top three things \\nthat you wish worked better? Why aren’t they working yet?” \\nFor example, if you want to apply AI to climate change, you \\nmight discover that power-grid operators can’t accurately \\npredict how much power intermittent sources like wind \\nand solar might generate in the future.\\nBrainstorm AI solutions. When I was younger, I used to \\nexecute on the first idea I was excited about. Sometimes \\nthis worked out okay, but sometimes I ended up missing \\nan even better idea that might not have taken any more \\neffort to build. Once you understand a problem, you can \\nbrainstorm potential solutions more efficiently. For instance, \\nto predict power generation from intermittent sources, we \\nmight consider using satellite imagery to map the locations \\nof wind turbines more accurately, using satellite imagery \\nto estimate the height and generation capacity of wind \\nturbines, or using weather data to better predict cloud cover \\nand thus solar irradiance. Sometimes there isn’t a good AI \\nsolution, and that’s okay too.\\nScoping Successful AI Projects CHAPTER 4\\nStep 1\\nStep 2\\n'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 15}, page_content='PAGE 16\\nDetermine milestones. Once you’ve deemed a project sufficiently \\nvaluable, the next step is to determine the metrics to aim for. This \\nincludes both machine learning metrics (such as accuracy) and \\nbusiness metrics (such as revenue). Machine learning teams are often \\nmost comfortable with metrics that a learning algorithm can optimize. \\nBut we may need to stretch outside our comfort zone to come up \\nwith business metrics, such as those related to user engagement, \\nrevenue, and so on. Unfortunately, not every business problem can be \\nreduced to optimizing test set accuracy! If you aren’t able to determine \\nreasonable milestones, it may be a sign that you need to learn more \\nabout the problem. A quick proof of concept can help supply the \\nmissing perspective.\\nAssess the feasibility and value of potential solutions. You can determine \\nwhether an approach is technically feasible by looking at published work, \\nwhat competitors have done, or perhaps building a quick proof of concept \\nimplementation. You can determine its value by consulting with domain \\nexperts (say, power-grid operators, who can advise on the utility of the \\npotential solutions mentioned above).\\nBudget for resources. Think through everything you’ll need to get the \\nproject done including data, personnel, time, and any integrations or \\nsupport you may need from other teams. For example, if you need funds \\nto purchase satellite imagery, make sure that’s in the budget.\\nWorking on projects is an iterative process. If, at any step, you find that the current direction is \\ninfeasible, return to an earlier step and proceed with your new understanding. Is there a domain \\nthat excites you where AI might make a difference? I hope these steps will guide you in exploring it \\nthrough project work — even if you don’t yet have deep expertise in that field. AI won’t solve every \\nproblem, but as a community, let’s look for ways to make a positive impact wherever we can.\\nScoping Successful AI Projects CHAPTER 4\\nStep 3\\nStep 4\\nStep 5'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 16}, page_content='PAGE 17\\nFinding Projects that \\nComplement Your \\nCareer Goals\\nCHAPTER 5\\nPROJECTS'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 17}, page_content='PAGE 18\\nIt goes without saying that we should only work on projects that are responsible, ethical, and \\nbeneficial to people. But those limits leave a large variety to choose from. In the previous chapter, \\nI wrote about how to identify and scope AI projects. This chapter and the next have a slightly \\ndifferent emphasis: picking and executing projects with an eye toward career development.\\nA fruitful career will include many projects, hopefully growing in scope, complexity, and impact \\nover time. Thus, it is fine to start small. Use early projects to learn and gradually step up to \\nbigger projects as your skills grow.\\nWhen you’re starting out, don’t expect others to hand great ideas or resources to you on a platter. \\nMany people start by working on small projects in their spare time. With initial successes — even \\nsmall ones — under your belt, your growing skills increase your ability to come up with better \\nideas, and it becomes easier to persuade others to help you step up to bigger projects.\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\\nJoin existing projects. If you find someone else with an idea, ask to join their project.\\nKeep reading and talking to people. I come up with new ideas whenever I spend a lot of \\ntime reading, taking courses, or talking with domain experts. I’m confident that you will, too.\\nFocus on an application area. Many researchers are trying to advance basic AI technology \\n— say, by inventing the next generation of transformers or further scaling up language \\nmodels — so, while this is an exciting direction, it is also very hard. But the variety of \\napplications to which machine learning has not yet been applied is vast! I’m fortunate to \\nhave been able to apply neural networks to everything from autonomous helicopter flight to \\nonline advertising, partly because I jumped in when relatively few people were working on \\nthose applications. If your company or school cares about a particular application, explore \\nthe possibilities for machine learning. That can give you a first look at a potentially creative \\napplication — one where you can do unique work — that no one else has done yet.\\n✓\\n✓\\n✓\\nWhat if you don’t have any project ideas?\\nHere are a few ways to generate them:'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 18}, page_content=\"PAGE 19\\nDevelop a side hustle. Even if you have a full-time job, a fun project that may or may not \\ndevelop into something bigger can stir the creative juices and strengthen bonds with \\ncollaborators. When I was a full-time professor, working on online education wasn’t part of \\nmy “job” (which was doing research and teaching classes). It was a fun hobby that I often \\nworked on out of passion for education. My early experiences in recording videos at home \\nhelped me later in working on online education in a more substantive way. Silicon Valley \\nabounds with stories of startups that started as side projects. As long as it doesn’t create a \\nconflict with your employer, these projects can be a stepping stone to something significant.\\nWill the project help you grow technically? Ideally, it should be challenging enough to \\nstretch your skills but not so hard that you have little chance of success. This will put you \\non a path toward mastering ever-greater technical complexity.\\nDo you have good teammates to work with? If not, are there people you can discuss things \\nwith? We learn a lot from the people around us, and good collaborators will have a huge \\nimpact on your growth.\\nCan it be a stepping stone?  If the project is successful, will its technical complexity and/\\nor business impact make it a meaningful stepping stone to larger projects? If the project \\nis bigger than those you’ve worked on before, there’s a good chance it could be such a \\nstepping stone.\\n✓\\n✓\\n✓\\n✓\\nGiven a few project ideas, which one should you jump into? \\nHere’s a quick checklist of factors to consider:\\nFinally, avoid analysis paralysis. It doesn’t make sense to spend a month deciding whether to \\nwork on a project that would take a week to complete. You'll work on multiple projects over \\nthe course of your career, so you’ll have ample opportunity to refine your thinking on what’s \\nworthwhile. Given the huge number of possible AI projects, rather than the conventional “ready, \\naim, fire” approach, you can accelerate your progress with “ready, fire, aim.”\\nFinding Projects that Compliment Your Career Goals CHAPTER 5\"),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 19}, page_content='PAGE 20\\nWorking on projects requires making tough choices about what to build and how to go \\nabout it. Here are two distinct styles:\\nSay you’ve built a customer-service chatbot for retailers, and you think it could help restaurants, \\ntoo. Should you take time to study the restaurant market before starting development, moving \\nslowly but cutting the risk of wasting time and resources? Or jump in right away, moving \\nquickly and accepting a higher risk of pivoting or failing?\\nBoth approaches have their advocates, and the best choice depends on the situation.\\nReady, Aim, Fire tends to be superior when the cost of execution is high and a study can shed \\nlight on how useful or valuable a project could be. For example, if you can brainstorm a few \\nother use cases (restaurants, airlines, telcos, and so on) and evaluate these cases to identify \\nthe most promising one, it may be worth taking the extra time before committing to a direction.\\nReady, Fire, Aim tends to be better if you can execute at low cost and, in doing so, determine \\nwhether the direction is feasible and discover tweaks that will make it work. For example, if \\nyou can build a prototype quickly to figure out if users want the product, and if canceling or \\npivoting after a small amount of work is acceptable, then it makes sense to consider jumping \\nin quickly. When taking a shot is inexpensive, it also makes sense to take many shots. In this \\ncase, the process is actually Ready, Fire, Aim, Fire, Aim, Fire, Aim, Fire. \\nAfter agreeing upon a project direction, when it comes to building a machine learning model \\nthat’s part of the product, I have a bias toward Ready, Fire, Aim. Building models is an iterative \\nprocess. For many applications, the cost of training and conducting error analysis is not \\nprohibitive. Furthermore, it is very difficult to carry out a study that will shed light on the \\nappropriate model, data, and hyperparameters. So it makes sense to build an end-to-end \\nsystem quickly and revise it until it works well.\\nBut when committing to a direction means making a costly investment or entering a one-\\nway door (meaning a decision that’s hard to reverse), it’s often worth spending more time in \\nadvance to make sure it really is a good idea.\\nReady, Fire, Aim\\nReady, Aim, Fire: Plan carefully and carry out careful validation. Commit and \\nexecute only when you have a high degree of confidence in a direction.\\nReady, Fire, Aim: Jump into development and start executing. This allows you to \\ndiscover problems quickly and pivot along the way if necessary.\\n✓\\n✓'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 20}, page_content='PAGE 21\\nBuilding a Portfolio of \\nProjects that Shows \\nSkill Progression \\nCHAPTER 6\\nPROJECTS'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 21}, page_content='PAGE 22\\nOver the course of a career, you’re likely to work on projects in succession, each growing in \\nscope and complexity. For example:\\nThe first few projects might be narrowly scoped \\nhomework assignments with predetermined right \\nanswers. These are often great learning experiences!\\nEventually, you will gain enough skill to build projects in \\nwhich others see more tangible value. This opens the door \\nto more resources. For example, rather than developing \\nmachine learning systems in your spare time, it might \\nbecome part of your job, and you might gain access to more \\nequipment, compute time, labeling budget, or head count.\\nYou might go on to work on small-scale projects either alone or with friends. \\nFor instance, you might re-implement a known algorithm, apply machine \\nlearning to a hobby (such as predicting whether your favorite sports team \\nwill win), or build a small but useful system at work in your spare time (such \\nas a machine learning-based script that helps a colleague automate some of \\ntheir work). Participating in competitions such as those organized by Kaggle \\nis also one way to gain experience.\\nSuccesses build on each other, opening the door to \\nmore technical growth, more resources, and increasingly \\nsignificant project opportunities.\\n1. Class projects:\\n3. Creating value\\n2. Personal projects\\n4. Rising scope and complexity\\nBuilding a Portfolio of Projects That Shows Skill Progression CHAPTER 6'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 22}, page_content='PAGE 23\\nEach project is only one step on a longer journey, hopefully one that has a positive impact. In addition:\\nDon’t worry about starting too small. One of my first machine learning research projects involved \\ntraining a neural network to see how well it could mimic the sin(x) function. It wasn’t very useful, but \\nwas a great learning experience that enabled me to move on to bigger projects.\\nBuilding a portfolio of projects, especially one \\nthat shows progress over time from simple to \\ncomplex undertakings, will be a big help when \\nit comes to looking for a job.\\nCommunication is key. You need to be able to explain your thinking if you want others to see \\nthe value in your work and trust you with resources that you can invest in larger projects. To get \\na project started, communicating the value of what you hope to build will help bring colleagues, \\nmentors, and managers onboard — and help them point out flaws in your reasoning. After you’ve \\nfinished, the ability to explain clearly what you accomplished will help convince others to open the \\ndoor to larger projects.\\nLeadership isn’t just for managers.  When you reach the point of working on larger AI projects that \\nrequire teamwork, your ability to lead projects will become more important, whether or not you are \\nin a formal position of leadership. Many of my friends have successfully pursued a technical rather \\nthan managerial career, and their ability to help steer a project by applying deep technical insights \\n— for example, when to invest in a new technical architecture or collect more data of a certain type \\n— allowed them to grow as leaders and also helped significantly improve the project.\\nBuilding a Portfolio of Projects That Shows Skill Progression CHAPTER 6'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 23}, page_content='PAGE 24\\nA Simple Framework \\nfor Starting Your AI \\nJob Search\\nCHAPTER 7\\nJOBS'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 24}, page_content='PAGE 25\\nFinding a job has a few predictable steps that include selecting the companies to which you \\nwant to apply, preparing for interviews, and finally picking a role and negotiating a salary and \\nbenefits. In this chapter, I’d like to focus on a framework that’s useful for many job seekers in \\nAI, especially those who are entering AI from a different field.\\nA product manager at a tech startup who becomes a data scientist at the same company (or a \\ndifferent one) has switched roles. A marketer at a manufacturing firm who becomes a marketer \\nin a tech company has switched industries. An analyst in a financial services company who \\nbecomes a machine learning engineer in a tech company has switched both roles and industries.\\nIf you’re looking for your first job in AI, you’ll probably find switching either roles or industries \\neasier than doing both at the same time. Let’s say you’re the analyst working in financial services:\\nIf you’re considering your next job, ask yourself:\\nJob \\nSearch\\nAre you switching roles? For example, if you’re a software engineer, \\nuniversity student, or physicist who’s looking to become a machine learning \\nengineer, that’s a role switch.\\nAre you switching industries? For example, if you work for a healthcare \\ncompany, financial services company, or a government agency and want \\nto work for a software company, that’s a switch in industries.\\n✓\\n✓\\nIf you find a data science or machine learning job in financial services, you can continue \\nto use your domain-specific knowledge while gaining knowledge and expertise in AI. After \\nworking in this role for a while, you’ll be better positioned to switch to a tech company (if \\nthat’s still your goal).\\nAlternatively, if you become an analyst in a tech company, you can continue to use your \\nskills as an analyst but apply them to a different industry. Being part of a tech company also \\nmakes it much easier to learn from colleagues about practical challenges of AI, key skills to \\nbe successful in AI, and so on.\\n✓\\n✓\\nA Simple Framework for Starting You AI Job Search CHAPTER 7\\nTECH\\nFINANCIAL \\nSERVICES Role & Industry Switch\\nRole Switch\\nIndustry Switch\\nANALYST MACHINE LEARNING \\nENGINEER'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 25}, page_content='PAGE 26\\nIf you’re considering a role switch, a startup can be an easier place to do it than a big company. \\nWhile there are exceptions, startups usually don’t have enough people to do all the desired \\nwork. If you’re able to help with AI tasks — even if it’s not your official job — your work is likely \\nto be appreciated. This lays the groundwork for a possible role switch without needing to leave \\nthe company. In contrast, in a big company, a rigid reward system is more likely to reward you \\nfor doing your job well (and your manager for supporting you in doing the job for which you were \\nhired), but it’s not as likely to reward contributions outside your job’s scope.\\nAfter working for a while in your desired role and industry (for example, a machine learning \\nengineer in a tech company), you’ll have a good sense of the requirements for that role in that \\nindustry at a more senior level. You’ll also have a network within that industry to help you along. \\nSo future job searches — if you choose to stick with the role and industry — likely will be easier.\\nWhen changing jobs, you’re taking a step into the unknown, particularly if you’re switching either \\nroles or industries. One of the most underused tools for becoming more familiar with a new role \\nand/or industry is the informational interview. I’ll share more about that in the next chapter.\\nI’m grateful to Salwa Nur Muhammad, CEO of FourthBrain (a DeepLearning.AI affiliate), for providing \\nsome of the ideas presented in this chapter.\\n'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 26}, page_content='PAGE 27\\nThere’s a lot we don’t know about the future: When will we cure Alzheimer’s disease? Who will \\nwin the next election? Or, in a business context, how many customers will we have next year?\\nWith so many changes going on in the world, many people are feeling stressed about the \\nfuture, especially when it comes to finding a job. I have a practice that helps me regain a sense \\nof control. Faced with uncertainty, I try to:\\nFor example, during the Covid-19 pandemic back in March 2020, I did this scenario planning \\nexercise. I imagined quick (three months), medium (one year), and slow (two years) recoveries \\nfrom Covid-19 and made plans for managing each case. These plans have helped me prioritize \\nwhere I can.\\nThe same method can apply to personal life, too. If you’re not sure you’ll pass an exam, get a \\njob offer, or be granted a visa — all of which can be stressful — you can write out what you’d \\ndo in each of the likely scenarios. Thinking through the possibilities and following through on \\nplans can help you navigate the future effectively no matter what it brings.\\nBonus: With training in AI and statistics, you can calculate a probability for each scenario. \\nI’m a fan of the Superforecasting methodology, in which the judgments of many experts are \\nsynthesized into a probability estimate. \\nOvercoming Uncertainty\\nMake a list of plausible scenarios, \\nacknowledging that I don’t know \\nwhich will come to pass.\\nCreate a plan of action \\nfor each scenario.\\nStart executing actions \\nthat seem reasonable.\\nReview scenarios and plans \\nperiodically as the future \\ncomes into focus.\\n1 2\\n3 4'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 27}, page_content='PAGE 28\\nUsing Informational \\nInterviews to Find \\nthe Right Job\\nCHAPTER 8\\nJOBS'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 28}, page_content='PAGE 29\\nIf you’re preparing to switch roles (say, taking a job as a machine learning engineer for the first \\ntime) or industries (say, working in an AI tech company for the first time), there’s a lot about \\nyour target job that you probably don’t know. A technique known as informational interviewing \\nis a great way to learn.\\nAn informational interview involves finding someone in a company or role you’d like to know \\nmore about and informally interviewing them about their work. Such conversations are separate \\nfrom searching for a job. In fact, it’s helpful to interview people who hold positions that align \\nwith your interests well before you’re ready to kick off a job search.\\nPrepare for informational interviews by researching the interviewee and company in advance, \\nso you can arrive with thoughtful questions. You might ask:\\nInformational interviews are particularly relevant to AI. Because the field is evolving, many \\ncompanies use job titles in inconsistent ways. In one company, data scientists might be \\nexpected mainly to analyze business data and present conclusions on a slide deck. In \\nanother, they might write and maintain production code. An informational interview can help \\nyou sort out what the AI people in a particular company actually do.\\nWith the rapid expansion of opportunities in AI, many people will be taking on an AI job for \\nthe first time. In this case, an informational interview can be invaluable for learning what \\nhappens and what skills are needed to do the job well. For example, you can learn what \\nalgorithms, deployment processes, and software stacks a particular company uses. You \\nmay be surprised — if you’re not already familiar with the data-centric AI movement — to \\nlearn how much time most machine learning engineers spend iteratively cleaning datasets.\\n✓\\n✓\\nWhat do you do in a typical week or day?\\nWhat are the most important tasks in this role?\\nWhat skills are most important for success?\\nHow does your team work together to accomplish its goals?\\nWhat is the hiring process?\\nConsidering candidates who stood out in the past, what enabled them to shine?\\n✓\\n✓\\n✓\\n✓\\n✓\\n✓\\nUsing Informational Interviews to Find the Right Job CHAPTER 8'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 29}, page_content='PAGE 30\\nFinding someone to interview isn’t always easy, but many people who are in senior positions today \\nreceived help when they were new from those who had entered the field ahead of them, and many \\nare eager to pay it forward. If you can reach out to someone who’s already in your network — \\nperhaps a friend who made the transition ahead of you or someone who attended the same school \\nas you — that’s great! Meetups such as Pie & AI can also help you build your network.\\nFinally, be polite and professional, and thank the people you’ve interviewed. And when you get \\na chance, please pay it forward as well and help someone coming up after you. If you receive \\na request for an informational interview from someone in the DeepLearning.AI community, \\nI hope you’ll lean in to help them take a step up! If you’re interested in learning more about \\ninformational interviews, I recommend this article from the UC Berkeley Career Center.\\nI’ve mentioned a few times the importance of your network and community. People you’ve \\nmet, beyond providing valuable information, can also play an invaluable role by referring you to \\npotential employers. \\nUsing Informational Interviews to Find the Right Job CHAPTER 8\\n'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 30}, page_content='PAGE 31\\nFinding the Right \\nAI Job for You\\nCHAPTER 9\\nJOBS'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 31}, page_content='PAGE 32\\nIn this chapter, I’d like to \\ndiscuss some fine points \\nof finding a job.\\nThe typical job search follows a fairly predictable path.\\nAlthough the process may be familiar, every job search is different. Here are some tips to increase \\nthe odds you’ll find a position that supports your thriving career and enables you to keep growing.\\nResearch roles and companies online or by talking to friends.\\nOptionally, arrange informal informational interviews with people in companies that appeal to you.\\nEither apply directly or, if you can, get a referral from someone on the inside.\\nInterview with companies that give you an invitation.\\nReceive one or more offers and pick one. Or, if you don’t receive an offer, ask for feedback \\nfrom the interviewers, human resources staff, online discussion boards, or anyone in your \\nnetwork who can help you plot your next move.\\n✓\\n✓\\n✓\\n✓\\n✓\\nPay attention to the fundamentals. A compelling resume, portfolio of technical projects, and \\na strong interview performance will unlock doors. Even if you have a referral from someone in a \\ncompany, a resume and portfolio will be your first contact with many people who don’t already \\nknow about you. Update your resume and make sure it clearly presents your education and \\nexperience relevant to the role you want. Customize your communications with each company \\nto explain why you’re a good fit. Before an interview, ask the recruiter what to expect. Take time \\nto review and practice answers to common interview questions, brush up key skills, and study \\ntechnical materials to make sure they are fresh in your mind. Afterward, take notes to help you \\nremember what was said.\\nProceed respectfully and responsibly. Approach interviews and offer negotiations with a win-\\nwin mindset. Outrage spreads faster than reasonableness on social media, so a story about \\nhow an employer underpaid someone gets amplified, whereas stories about how an employer \\ntreated someone fairly do not. The vast majority of employers are ethical and fair, so don’t let \\nstories about the small fraction of mistreated individuals sway your approach. If you’re leaving \\na job, exit gracefully. Give your employer ample notice, give your full effort through your last \\nhour on the job, transition unfinished business as best you can, and leave in a way that honors \\nthe responsibilities you were entrusted with.\\nFinding the Right AI Job For You CHAPTER 9'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 32}, page_content='PAGE 33\\nChoose who to work with. It’s tempting to take a position because of the projects you’ll work \\non. But the teammates you’ll work with are at least equally important. We’re influenced by \\npeople around us, so your colleagues will make a big difference. For example, if your friends \\nsmoke, the odds increase that you, too, will smoke. I don’t know of a study that shows this, \\nbut I’m pretty sure that if most of your colleagues work hard, learn continuously, and build AI \\nto benefit all people, you’re likely to do the same. (By the way, some large companies won’t \\ntell you who your teammates will be until you’ve accepted an offer. In this case, be persistent \\nand keep pushing to identify and speak with potential teammates. Strict policies may make it \\nimpossible to accommodate you, but in my mind, that increases the risk of accepting the offer, \\nas it increases the odds you’ll end up with a manager or teammates who aren’t a good fit.)\\nGet help from your community. Most of us go job hunting only a small number of times in our \\ncareers, so few of us get much practice at doing it well. Collectively, though, people in your \\nimmediate community probably have a lot of experience. Don’t be shy about calling on them. \\nFriends and associates can provide advice, share inside knowledge, and refer you to others \\nwho may help. I got a lot of help from supportive friends and mentors when I applied for my \\nfirst faculty position, and many of the tips they gave me were very helpful.\\nI know that the job-search process can be intimidating. Instead of viewing it as a great leap, \\nconsider an incremental approach. Start by identifying possible roles and conducting a handful \\nof informational interviews. If these conversations tell you that you have more learning to do \\nbefore you’re ready to apply, that’s great! At least you have a clear path forward. The most \\nimportant part of any journey is to take the first step, and that step can be a small one.\\nFinding the Right AI Job For You CHAPTER 9'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 33}, page_content='PAGE 34\\nKeys to Building a \\nCareer in AI\\nCHAPTER 10\\nJOBS'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 34}, page_content='PAGE 35\\nKeys to Building a Career in AI CHAPTER 10\\nThe path to career success in AI is more complex than what I can  cover in one short eBook. \\nHopefully the previous chapters will give you momentum to move forward. \\nHere are additional things to think about as you plot your path to success: \\nWhen we tackle large projects, we succeed better by \\nworking in teams than individually. The ability to collaborate \\nwith, influence, and be influenced by others is critical. \\nThus, interpersonal and communication skills really matter. \\n(I used to be a pretty bad communicator, by the way.)\\n1. Teamwork:\\nI hate networking! As an introvert, having to go to a party \\nto smile and shake as many hands as possible is an activity \\nthat borders on horrific. I’d much rather stay home and read \\na book. Nonetheless, I’m fortunate to have found many \\ngenuine friends in AI; people I would gladly go to bat for \\nand who I count on as well. No person is an island, and \\nhaving a strong professional network can help propel you \\nforward in the moments when you need help or advice. In \\nlieu of networking, I’ve found it more helpful to think about \\nbuilding up a community. So instead of trying to build up \\nmy personal network, I focus instead on building up the \\ncommunities that I’m part of. This has the side effect of \\nhelping me meet more people and make friends as well. \\n2. Networking:\\n'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 35}, page_content='PAGE 36\\nKeys to Building a Career in AI CHAPTER 10\\nOf all the steps in building a career, this \\none tends to receive the most attention. \\nUnfortunately, there is a lot of bad advice \\nabout this on the internet. (For example, many \\narticles urge taking an adversarial attitude \\ntoward potential employers, which I don’t think \\nis helpful.) Although it may seem like finding a \\njob is the ultimate goal, it’s just one small step \\nin the long journey of a career.\\n3. Job search\\nFew people will know whether you spend \\nyour weekends learning, or binge watching \\nTV — but they will notice the difference over \\ntime. Many successful people develop good \\nhabits in eating, exercise, sleep, personal \\nrelationships, work, learning, and self-care. \\nSuch habits help them move forward while \\nstaying healthy.\\n4. Personal discipline\\nI find that people  who aim to lift others during \\nevery step of their own journey often achieve \\nbetter outcomes for themselves. How can we \\nhelp others even as we build an exciting career \\nfor ourselves?\\n5. Altruism\\n'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 36}, page_content='PAGE 37\\nOvercoming Imposter \\nSyndrome\\nCHAPTER 11'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 37}, page_content='PAGE 38\\nBefore we dive into the final chapter of this book, I’d like to address the serious matter of \\nnewcomers to AI sometimes experiencing imposter syndrome, where someone — regardless \\nof their success in the field — wonders if they’re a fraud and really belong in the AI community. \\nI want to make sure this doesn’t discourage you or anyone else from growing in AI.\\nAn estimated 70 percent of people experience some form of imposter syndrome at some point. \\nMany talented people have spoken publicly about this experience, including former Facebook \\nCOO Sheryl Sandberg, U.S. first lady Michelle Obama, actor Tom Hanks, and Atlassian co-CEO \\nMike Cannon-Brookes. It happens in our community even among accomplished people. If you’ve \\nnever experienced this yourself, that’s great! I hope you’ll join me in encouraging and welcoming \\neveryone who wants to join our community.\\nAI is technically complex, and it has its fair share of smart and highly capable people. But it is \\neasy to forget that to become good at anything, the first step is to suck at it. If you’ve succeeded \\nat sucking at AI — congratulations, you’re on your way!\\nI once struggled to understand the math behind linear regression. I was mystified when \\nlogistic regression performed strangely on my data, and it took me days to find a bug in my \\nimplementation of a basic neural network. Today, I still find many research papers challenging \\nto read, and I recently made an obvious mistake while tuning a neural network hyperparameter \\n(that fortunately a fellow engineer caught and fixed).\\nSo if you, too, find parts of AI challenging, it’s okay. We’ve all been there. I guarantee that everyone \\nwho has published a seminal AI paper struggled with similar technical challenges at some point.\\nLet me be clear: If you want to be part of the AI \\ncommunity, then I welcome you with open arms. \\nIf you want to join us, you fully belong with us!\\nOvercoming Imposter Syndrome'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 38}, page_content='PAGE 39\\nMy three-year-old daughter (who can barely count to 12) regularly tries to teach things to my \\none-year-old son. No matter how far along you are — if you’re at least as knowledgeable as a \\nthree-year-old — you can encourage and lift up others behind you. Doing so will help you, too, \\nas others behind you will recognize your expertise and also encourage you to keep developing. \\nWhen you invite others to join the AI community, which I hope you will do, it also reduces any \\ndoubts that you are already one of us.\\nAI is such an important part of our world that I would like everyone who wants to be part of it \\nto feel at home as a member of our community. Let’s work together to make it happen.\\nHere are some things that can help.\\nDo you have supportive mentors or peers? If you don’t yet, attend Pie & AI or other events, \\nuse discussion boards, and work on finding some. If your mentors or manager don’t support \\nyour growth, find ones who do. I’m also working on how to grow a supportive AI community \\nand hope to make finding and giving support easier for everyone.\\nNo one is an expert at everything. Recognize what you do well. If what you do well is \\nunderstand and explain to your friends one-tenth of the articles in The Batch, then you’re \\non your way! Let’s work on getting you to understand two-tenths of the articles.\\n✓\\n✓\\nOvercoming Imposter Syndrome'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 39}, page_content='PAGE 40\\nMake Every Day Count\\nFinal Thoughts\\nEvery year on my birthday, I get to thinking about the days behind and those \\nthat may lie ahead.\\nWhen I ask friends, many choose a number in the hundreds of \\nthousands. (Many others can’t resist calculating the answer, \\nto my annoyance!)\\nWhen I was a grad student, I remember plugging my statistics \\ninto a mortality calculator to figure out my life expectancy. \\nThe calculator said I could expect to live a total of 27,649 \\ndays. It struck me how small this number is. I printed it in a \\nlarge font and pasted it on my office wall as a daily reminder.\\nThat’s all the days we have to spend with loved ones, learn, \\nbuild for the future, and help others. Whatever you’re doing \\ntoday, is it worth 1/30,000 of your life?\\nHow many days is a \\ntypical human lifespan?\\nMaybe you’re good at math; I’m sure you’ll be able to answer the following question \\nvia a quick calculation. But let me ask you a question, and please answer from \\nyour gut, without calculating.\\n20,000 days 100,000 days\\n1 million days 5 million days'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 40}, page_content='PAGE 41\\n')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chunking"
      ],
      "metadata": {
        "id": "qyvt7FcmBAIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=10, chunk_overlap=1 , separator=\"\")\n",
        "texts = text_splitter.split_documents(text_doc) # the  docs var contain many documents to  split"
      ],
      "metadata": {
        "id": "QyMiWp9M0VK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4tEuADv7om8",
        "outputId": "2ff86a69-54eb-4934-e869-b6930e45ebe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'speech.txt'}, page_content='In the eve'),\n",
              " Document(metadata={'source': 'speech.txt'}, page_content='er-evolvin'),\n",
              " Document(metadata={'source': 'speech.txt'}, page_content='ng world o')]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200 , separator=\"\")\n",
        "texts = text_splitter.split_documents(docs) # the  docs var contain many documents to  split"
      ],
      "metadata": {
        "id": "nic92CrnFNPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1JZNt2LFzI2",
        "outputId": "c00e6382-b9a9-4003-9fc4-ef4218cb8d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'book.pdf', 'page': 0}, page_content='PAGE 1\\nFounder, DeepLearning.AI\\nCollected Insights\\nfrom Andrew Ng\\nHow to \\nBuild\\nYour\\nCareer\\nin AI\\nA Simple Guide'),\n",
              " Document(metadata={'source': 'book.pdf', 'page': 1}, page_content='PAGE 2\\n\"AI is the new \\nelectricity. It will \\ntransform and improve \\nall areas of human life.\"\\nAndrew Ng')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3PCwRC7SKZCt",
        "outputId": "df0c26dc-2b56-4a6e-e08e-7868624261cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (0.6.3)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.5)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.7.6)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.8.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.29.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.69.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (31.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.14)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.95.2->chromadb) (0.41.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.9.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "text_splitter = CharacterTextSplitter(chunk_size=200 , chunk_overlap=10)\n",
        "texts = text_splitter.split_documents(text_doc)\n",
        "print(texts)\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents( texts ,embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm4JnAoqF2BA",
        "outputId": "a206c4b6-97a6-4daf-9224-6ecf6950a273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_text_splitters.base:Created a chunk of size 374, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 342, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 345, which is longer than the specified 200\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 351, which is longer than the specified 200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'speech.txt'}, page_content='In the ever-evolving world of artificial intelligence, machine learning has emerged as one of the most influential fields. It encompasses a variety of techniques, including supervised, unsupervised, and reinforcement learning. Each of these methods serves a distinct purpose in solving complex problems, from predicting future trends to optimizing decision-making processes.'), Document(metadata={'source': 'speech.txt'}, page_content='Supervised learning, one of the most common techniques, involves training a model on labeled data to make predictions or classifications. This approach is widely used in fields like healthcare, finance, and marketing. For example, in healthcare, machine learning models can predict the likelihood of diseases based on historical patient data.'), Document(metadata={'source': 'speech.txt'}, page_content='Unsupervised learning, on the other hand, focuses on identifying patterns and structures within data without prior labeling. It is often applied in scenarios like customer segmentation, where the goal is to discover hidden groupings within a dataset. Techniques such as clustering and dimensionality reduction are commonly used in this approach.'), Document(metadata={'source': 'speech.txt'}, page_content='Reinforcement learning is a type of learning that is based on trial and error. An agent interacts with an environment, making decisions and receiving rewards or penalties based on those actions. Over time, the agent learns to make better decisions to maximize its rewards. This approach has been used in robotics, game-playing, and autonomous systems.'), Document(metadata={'source': 'speech.txt'}, page_content='As AI continues to advance, new methodologies and applications are being developed, driving innovation across industries. The integration of machine learning into everyday technology is transforming how businesses operate and how individuals interact with technology.\\nMachine Learning (ML) is a subset of artificial intelligence (AI) that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data, without being explicitly programmed. Machine learning systems use data to identify patterns and insights, improving their performance over time as they are exposed to more data.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quety = \"what is   machine learning  ?\"\n",
        "result = db.similarity_search(quety)\n",
        "result[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "-2PwoZjKOOuu",
        "outputId": "9d73c932-35f3-402b-b4cb-bf4092011f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As AI continues to advance, new methodologies and applications are being developed, driving innovation across industries. The integration of machine learning into everyday technology is transforming how businesses operate and how individuals interact with technology.\\nMachine Learning (ML) is a subset of artificial intelligence (AI) that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data, without being explicitly programmed. Machine learning systems use data to identify patterns and insights, improving their performance over time as they are exposed to more data.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using faiss db\n",
        "from langchain_community.vectorstores import FAISS\n",
        "db1 = FAISS.from_documents( texts ,embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))"
      ],
      "metadata": {
        "id": "SqLw1Q-nOOsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quety = \"what is   machine learning  ?\"\n",
        "result = db1.similarity_search(quety)\n",
        "result[0].page_content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "hCwGrKAFOOpk",
        "outputId": "078146b6-9189-4088-9b68-166e8fb28c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As AI continues to advance, new methodologies and applications are being developed, driving innovation across industries. The integration of machine learning into everyday technology is transforming how businesses operate and how individuals interact with technology.\\nMachine Learning (ML) is a subset of artificial intelligence (AI) that involves the development of algorithms and statistical models that enable computers to learn from and make predictions or decisions based on data, without being explicitly programmed. Machine learning systems use data to identify patterns and insights, improving their performance over time as they are exposed to more data.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uikDf-_iOOnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eSr_an3VOOkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NjHCn45MOOhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HNYjseKeOMqn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}